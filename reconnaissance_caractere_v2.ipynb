{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from skimage.io import imshow, imread\n",
    "from skimage import transform\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.util import img_as_ubyte\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics.pairwise import pairwise_distances_argmin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "class Character():\n",
    "    def __init__(self, matrix, description=\"\"):\n",
    "        self.matrix = matrix\n",
    "        self.description = description\n",
    "        self.reduced_vector = None\n",
    "        \n",
    "    def resize(self, width:int = 20):\n",
    "        \"\"\"Resize en fonction d'une seule dimension seulement\"\"\"\n",
    "        # Calculer la nouvelle largeur pour préserver les proportions\n",
    "        aspect_ratio = self.matrix.shape[1] / self.matrix.shape[0]\n",
    "        new_height = int(width * aspect_ratio)\n",
    "        \n",
    "        scaled_image = transform.resize(self.matrix, (new_height, width), preserve_range=True)\n",
    "        \n",
    "        self.matrix = (scaled_image).astype(np.uint8)\n",
    "    \n",
    "    def binarisation(self):\n",
    "        thresh = threshold_otsu(self.matrix)\n",
    "        binary = self.matrix > thresh\n",
    "        self.matrix = 255 * binary\n",
    "        \n",
    "    def cadrage(self):\n",
    "        \"\"\"https://stackoverflow.com/questions/4808221/is-there-a-bounding-box-function-slice-with-non-zero-values-for-a-ndarray-in\n",
    "        Plus Llama 3 pour débuggage\n",
    "        \"\"\"\n",
    "        rows = np.any(self.matrix == 0, axis=1)\n",
    "        cols = np.any(self.matrix == 0, axis=0)\n",
    "        ymin, ymax = np.where(rows)[0][[0, -1]]\n",
    "        xmin, xmax = np.where(cols)[0][[0, -1]]\n",
    "        self.matrix = self.matrix[ymin:ymax+1, xmin:xmax+1]\n",
    "\n",
    "    def padding(self, dimensions:tuple = (60, 60)):\n",
    "        \"\"\"Permet d'avoir une matrice de dimensions fixe en ajoutant des 0\n",
    "        Codé par Llama 3\n",
    "        Non testé si l'array self.matrix est plus grand que dimensions ! Peut être ajouter aussi un downscaling dans ce cas\n",
    "        \"\"\"\n",
    "        h, w = self.matrix.shape\n",
    "        new_arr = np.zeros(dimensions, dtype=self.matrix.dtype)\n",
    "        new_arr[:h, :w] = self.matrix\n",
    "        self.matrix = new_arr\n",
    "    \n",
    "    def traitement(self):\n",
    "        self.binarisation()\n",
    "        self.cadrage()\n",
    "        self.padding()\n",
    "    \n",
    "    def reduce_dimension(self, pca_instance):\n",
    "        \"\"\"A tester. Enregistre le vecteur réduit comme un attribut\"\"\"\n",
    "        self.reduced_vector = pca_instance.transform(np.array([np.ravel(self.matrix)]))[0]\n",
    "    \n",
    "    def affiche_matrice(self):\n",
    "        \"\"\"Permet d'afficher la matrice\"\"\"\n",
    "        plt.imshow(self.matrix, cmap=\"gray\")\n",
    "    \n",
    "    def get_Hu_moments_v2(self):\n",
    "        \"\"\"From https://scikit-image.org/docs/stable/api/skimage.measure.html#skimage.measure.moments_hu\"\"\"\n",
    "        mu = moments_central(self.matrix)\n",
    "        nu = moments_normalized(mu)\n",
    "        return moments_hu(nu)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifieur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifieur():\n",
    "    def __init__(self, n):\n",
    "        self.pca = PCA(n_components=n)\n",
    "        self.lettres_references = {}    # Dictionnaire qui associe à un caractère la liste des instances character\n",
    "        self.reference = {} # Dictionnaire qui associe à un caractère la liste des vecteurs réduits\n",
    "        self.centers = {}   # Dictionnaire qui associe à un caractère le vecteur moyen des vecteurs réduit de ce caractère\n",
    "\n",
    "                \n",
    "    def load_data_degraded(self, folder_path):\n",
    "        \"\"\"Rempli le dictionnaire self.lettres_references\n",
    "        \n",
    "        Le format des fichiers attendu est \"lettre_indice.png\" \n",
    "        \n",
    "        \"\"\"\n",
    "        self.lettres_references = {}\n",
    "                \n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tif')):\n",
    "                img_path = os.path.join(folder_path, filename)\n",
    "                img = imread(img_path, as_gray=True)\n",
    "                # On ajoute dans le dictionnaire\n",
    "                self.lettres_references[filename.split(\".\")[0].split(\"_\")[0]] = self.lettres_references.get(filename.split(\".\")[0], [])\n",
    "                self.lettres_references[filename.split(\".\")[0].split(\"_\")[0]].append(Character(img, filename.split(\".\")[0]))\n",
    "\n",
    "        # Pour toutes les lettres, on effectue le traitement\n",
    "        for lst_lettres in self.lettres_references.values():\n",
    "            for lettre in lst_lettres:\n",
    "                lettre.traitement()\n",
    "    \n",
    "    def generate_data_set(self):\n",
    "        \"\"\"Formatte les données pour le PCA. Renvoie un array de la forme (n_samples, n_features)\"\"\"\n",
    "        data_set = []\n",
    "        for lst_lettres in self.lettres_references.values():\n",
    "            for lettre in lst_lettres:\n",
    "                data_set.append(np.ravel(lettre.matrix))\n",
    "        return np.array(data_set)\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Génère le data set et entraîne le PCA\"\"\"\n",
    "        data_set = self.generate_data_set()\n",
    "        self.pca.fit(data_set)\n",
    "\n",
    "        for lettre, lst_lettres in self.lettres_references.items():\n",
    "            for instance_character in lst_lettres:\n",
    "                # On réduit de dimension la matrice du caractère. Le vecteur réduit est stocké dans l'instance\n",
    "                # de la classe Character\n",
    "                instance_character.reduce_dimension(self.pca)\n",
    "                \n",
    "                # On enregistre dans le dico self.reference\n",
    "                self.reference[lettre] = self.reference.get(lettre, [])\n",
    "                self.reference[lettre].append(instance_character.reduced_vector)\n",
    "        \n",
    "    \n",
    "    def generate_center_dict(self):\n",
    "        for lettre, lst_vecteur in self.reference.items():\n",
    "            arrays = []\n",
    "            for vecteur in lst_vecteur:\n",
    "                arrays.append(vecteur)\n",
    "            vecteur_moyen = np.mean(np.array(arrays), axis=0)\n",
    "            self.centers[lettre] = vecteur_moyen\n",
    "    \n",
    "    def compare(self, unknown):\n",
    "        \"\"\"Dis de quel centre le caractère est le plus procher\"\"\"\n",
    "        # On applique les traitements au caractère inconnu\n",
    "        unknown.traitement()\n",
    "        \n",
    "        # On calcule le vecteur réduit le caractérisant\n",
    "        unknown.reduce_dimension(self.pca)\n",
    "        \n",
    "        # On trouve de quel centre il est le plus proche\n",
    "        Y = np.array([vector for vector in self.centers.values()])\n",
    "        \n",
    "        most_near_center_vector = Y[pairwise_distances_argmin(np.array([unknown.reduced_vector]), Y)[0]]\n",
    "        \n",
    "        for x, y in self.centers.items():\n",
    "            if np.all(y == most_near_center_vector):\n",
    "                return x\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple d'utilisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t\n"
     ]
    }
   ],
   "source": [
    "c = Classifieur(20)\n",
    "c.load_data_degraded(\"~/klem/degrade\")\n",
    "c.train()\n",
    "c.generate_center_dict()\n",
    "\n",
    "# Ouverture d'une lettre\n",
    "im = imread(\"t.png\", as_gray=True)\n",
    "a = Character(im, \"\")\n",
    "a.traitement()\n",
    "print(c.compare(a))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
